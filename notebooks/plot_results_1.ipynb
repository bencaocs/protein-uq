{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1a1f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n",
    "os.chdir(\"../src/models/results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e08920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"dataset\",\n",
    "    \"split\",\n",
    "    \"representation\",\n",
    "    \"model\",\n",
    "    \"uncertainty\",\n",
    "    \"dropout\",\n",
    "    \"train_rho\",\n",
    "    \"train_rmse\",\n",
    "    \"train_mae\",\n",
    "    \"train_r2\",\n",
    "    \"test_rho\",\n",
    "    \"test_rmse\",\n",
    "    \"test_mae\",\n",
    "    \"test_r2\",\n",
    "    \"train_rho_unc\",\n",
    "    \"train_p_rho_unc\",\n",
    "    \"train_percent_coverage\",\n",
    "    \"train_average_width_range\",\n",
    "    \"train_miscalibration_area\",\n",
    "    \"train_average_nll\",\n",
    "    \"train_average_optimal_nll\",\n",
    "    \"train_average_nll_ratio\",\n",
    "    \"test_rho_unc\",\n",
    "    \"test_p_rho_unc\",\n",
    "    \"test_percent_coverage\",\n",
    "    \"test_average_width_range\",\n",
    "    \"test_miscalibration_area\",\n",
    "    \"test_average_nll\",\n",
    "    \"test_average_optimal_nll\",\n",
    "    \"test_average_nll_ratio\",\n",
    "    \"crossval_idx\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf14b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "aav_results_df = pd.read_csv(\"aav_results.csv\", header=None, names=column_names)\n",
    "gb1_results_df = pd.read_csv(\"gb1_results.csv\", header=None, names=column_names)\n",
    "meltome_results_df = pd.read_csv(\"meltome_results.csv\", header=None, names=column_names)\n",
    "\n",
    "results_df = pd.concat([aav_results_df, gb1_results_df, meltome_results_df]).reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep most recent result if more than one is present\n",
    "results_df.drop_duplicates(subset=[\"dataset\", \n",
    "                                   \"split\", \n",
    "                                   \"representation\", \n",
    "                                   \"model\", \n",
    "                                   \"uncertainty\", \n",
    "                                   \"dropout\",\n",
    "                                   \"crossval_idx\"], keep=\"last\", inplace=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496bdf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keey dropout with lowest train miscalibration area\n",
    "results_df = results_df.sort_values('train_miscalibration_area', ascending=True)\n",
    "results_df.drop_duplicates(subset=[\"dataset\", \n",
    "                                    \"split\", \n",
    "                                    \"representation\", \n",
    "                                    \"model\", \n",
    "                                    \"uncertainty\",\n",
    "                                    \"crossval_idx\"],\n",
    "                             keep=\"first\", \n",
    "                             inplace=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259277d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_mean = results_df.groupby([\"dataset\", \n",
    "                                    \"split\", \n",
    "                                    \"representation\", \n",
    "                                    \"model\", \n",
    "                                    \"uncertainty\"]).mean()\n",
    "\n",
    "results_df_std = results_df.groupby([\"dataset\", \n",
    "                                    \"split\", \n",
    "                                    \"representation\", \n",
    "                                    \"model\", \n",
    "                                    \"uncertainty\"]).std()\n",
    "results_df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ce976",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df_mean.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a9d54a",
   "metadata": {},
   "source": [
    "# Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63569403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_model_name(row):\n",
    "    if row.model == \"cnn\":\n",
    "        if row.uncertainty == \"dropout\":\n",
    "            name = \"CNN Dropout\"\n",
    "        elif row.uncertainty == \"ensemble\":\n",
    "            name = \"CNN Ensemble\"\n",
    "        elif row.uncertainty == \"evidential\":\n",
    "            name = \"CNN Evidential\"\n",
    "        elif row.uncertainty == \"mve\":\n",
    "            name = \"CNN MVE\"\n",
    "        elif row.uncertainty == \"svi\":\n",
    "            name = \"CNN SVI\"\n",
    "        else:\n",
    "            raise ValueError(\"not implemented\")\n",
    "    elif row.model == \"gp\":\n",
    "        name = \"GP Continuous\"\n",
    "    elif row.model == \"ridge\":\n",
    "        name = \"Linear Bayesian Ridge\"\n",
    "    else: \n",
    "        raise ValueError(\"not implemented\")\n",
    "    return name\n",
    "\n",
    "results_df[\"Model\"] = results_df.apply(get_full_model_name, axis=1)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f9b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make names look nice for plot legend\n",
    "\n",
    "dataset_names_dict = {\n",
    "    'aav':'AAV',\n",
    "    'meltome':'Meltome',\n",
    "    'gb1':'GB1',\n",
    "}\n",
    "\n",
    "model_names_dict = {\n",
    "    'CNN_dropout':'CNN Dropout',\n",
    "    'CNN_ensemble':'CNN Ensemble',\n",
    "    'CNN_evidential':'CNN Evidential',\n",
    "    'CNN_mve':'CNN MVE',\n",
    "    'CNN_svi':'CNN SVI',\n",
    "    'linearBayesianRidge':'Linear Bayesian Ridge',\n",
    "    'GPcontinuous':'GP Continuous',\n",
    "}\n",
    "\n",
    "split_names_dict = {\n",
    "    'sampled':'Random',\n",
    "    'seven_vs_many':'7 vs. Rest',\n",
    "    'mut_des':'Sampled vs. Designed',\n",
    "    'mixed_split':'Random',\n",
    "    'three_vs_rest':'3 vs. Rest',\n",
    "    'two_vs_rest':'2 vs. Rest',\n",
    "    'one_vs_rest':'1 vs. Rest',\n",
    "}\n",
    "\n",
    "results_df['Dataset'] = results_df['dataset'].map(dataset_names_dict)\n",
    "results_df['Split'] = results_df['split'].map(split_names_dict)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156a535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "results_df.sort_values(['train_rho'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7087aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_rank_dict = {\n",
    "    'aav': 0,\n",
    "    'meltome': 1,\n",
    "    'gb1': 2,\n",
    "}\n",
    "\n",
    "split_rank_dict = {\n",
    "    'sampled': 0,\n",
    "    'mixed_split': 1,\n",
    "    'seven_vs_many': 2,\n",
    "    'mut_des': 3,\n",
    "    'three_vs_rest': 4,\n",
    "    'two_vs_rest': 5,\n",
    "    'one_vs_rest': 6,\n",
    "}\n",
    "\n",
    "model_rank_dict = {\n",
    "    'Linear Bayesian Ridge': 0,\n",
    "    'CNN Ensemble': 1,\n",
    "    'CNN MVE': 2,\n",
    "    'CNN Dropout': 3,\n",
    "    'GP Continuous': 4,\n",
    "    'CNN Evidential': 5,\n",
    "    'CNN SVI': 6,\n",
    "}\n",
    "\n",
    "rep_rank_dict = {\n",
    "    'ohe': 0,\n",
    "    'esm': 1,\n",
    "}\n",
    "\n",
    "results_df['dataset_rank'] = results_df['dataset'].map(dataset_rank_dict)\n",
    "results_df['split_rank'] = results_df['split'].map(split_rank_dict)\n",
    "results_df['model_rank'] = results_df['Model'].map(model_rank_dict)\n",
    "results_df['rep_rank'] = results_df['representation'].map(rep_rank_dict)\n",
    "\n",
    "results_df.sort_values(['model_rank', 'dataset_rank', 'split_rank', 'rep_rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862ba4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aav_df = results_df.loc[results_df['Dataset']=='AAV']\n",
    "meltome_df = results_df.loc[results_df['Dataset']=='Meltome']\n",
    "gb1_df = results_df.loc[results_df['Dataset']=='GB1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3794448",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dataset_case(dataset_name):\n",
    "    if dataset_name in [\"aav\", \"gb1\"]:\n",
    "        dataset_name = dataset_name.upper()\n",
    "    elif dataset_name == \"meltome\":\n",
    "        dataset_name = \"Meltome\"\n",
    "    elif 'f' in dataset_name:\n",
    "        dataset_name = dataset_name\n",
    "    else:\n",
    "        raise ValueError\n",
    "    return dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930ca935",
   "metadata": {},
   "source": [
    "### OHE vs. ESM Summary Heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aa8010",
   "metadata": {},
   "source": [
    "#### Figure S4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_label_dict = {\n",
    "    'test_rho': r\"Test $\\rho$\",\n",
    "    'test_rho_unc': r\"Test $\\rho_{unc}$\",\n",
    "               }\n",
    "\n",
    "figs, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "\n",
    "# rho\n",
    "ohe_vs_esm_df = pd.pivot_table(results_df, values='test_rho', index=['Dataset','Split','Model'],\n",
    "                columns=['representation'], aggfunc=np.mean)\n",
    "\n",
    "ohe_vs_esm_df['diff'] = ohe_vs_esm_df.esm - ohe_vs_esm_df.ohe\n",
    "\n",
    "print(f\"ESM performs better than OHE {sum(ohe_vs_esm_df['diff']>0)} out of {ohe_vs_esm_df['diff'].count()} times for test_rho\")\n",
    "\n",
    "df_pivot = ohe_vs_esm_df.reset_index().pivot(index=['Dataset','Split'], \n",
    "                               columns='Model', \n",
    "                               values='diff')\n",
    "\n",
    "sns.heatmap(df_pivot, \n",
    "            annot=True, \n",
    "            linewidth=0.5,\n",
    "            cmap='vlag',\n",
    "            ax=axs[0],\n",
    "           cbar_kws={\n",
    "               'label': f\"ESM - OHE Difference ({col_to_label_dict['test_rho']})\",\n",
    "           }, \n",
    "           )\n",
    "\n",
    "\n",
    "# rho_unc\n",
    "ohe_vs_esm_df = pd.pivot_table(results_df, values='test_rho_unc', index=['Dataset','Split','Model'],\n",
    "                columns=['representation'], aggfunc=np.mean)\n",
    "\n",
    "ohe_vs_esm_df['diff'] = ohe_vs_esm_df.esm - ohe_vs_esm_df.ohe\n",
    "\n",
    "print(f\"ESM performs better than OHE {sum(ohe_vs_esm_df['diff']>0)} out of {ohe_vs_esm_df['diff'].count()} times for test_rho_unc\")\n",
    "\n",
    "df_pivot = ohe_vs_esm_df.reset_index().pivot(index=['Dataset','Split'], \n",
    "                               columns='Model', \n",
    "                               values='diff')\n",
    "\n",
    "sns.heatmap(df_pivot, \n",
    "            annot=True, \n",
    "            linewidth=0.5,\n",
    "            cmap='vlag',\n",
    "            ax=axs[1],\n",
    "           cbar_kws={\n",
    "               'label': f\"ESM - OHE Difference ({col_to_label_dict['test_rho_unc']})\",\n",
    "           }, \n",
    "           )\n",
    "    \n",
    "    \n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.5, hspace=1)  \n",
    "plt.savefig(f\"esm_minus_ohe_heatmap.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f0fc02",
   "metadata": {},
   "source": [
    "### Accuracy vs. Calibration, Sharpness vs. Dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0bf39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_vars(x, y):\n",
    "    \n",
    "    palette = {\n",
    "            \"CNN Dropout\": \"tab:blue\",\n",
    "            \"CNN Ensemble\": \"tab:orange\",\n",
    "            \"CNN Evidential\": \"tab:green\",\n",
    "            \"CNN MVE\": \"tab:red\",\n",
    "            \"CNN SVI\": \"tab:purple\",\n",
    "            \"GP Continuous\": \"tab:brown\",\n",
    "            \"Linear Bayesian Ridge\": \"tab:pink\",\n",
    "        }\n",
    "    \n",
    "    for landscape, landscape_df_ in zip(['GB1','AAV','Meltome'], [gb1_df, aav_df, meltome_df]):\n",
    "        for representation in [\"ohe\", \"esm\"]:\n",
    "            landscape_df_rep = landscape_df_.loc[landscape_df_.representation==representation]\n",
    "            landscape_df = landscape_df_rep.sort_values(['split_rank','Model'])\n",
    "            \n",
    "            if y.endswith(\"percent_coverage\"):\n",
    "                plt.axhline(0.95, ls='--', c='k', lw=1)\n",
    "                \n",
    "            sns.scatterplot(data=landscape_df,\n",
    "                            x=x,\n",
    "                            y=y,\n",
    "                            hue='Model',\n",
    "                            style='Split',\n",
    "                            palette=palette,\n",
    "                            s=100,\n",
    "                            alpha=0.8)\n",
    "\n",
    "            if x.endswith(\"rmse\"):\n",
    "                plt.xlabel(r\"RMSE ($\\leftarrow$)\", fontsize=15)\n",
    "                x_ = \"rmse\"\n",
    "            elif x.endswith(\"average_width_range\"):\n",
    "                plt.xlabel(r\"Average Width / Range ($\\leftarrow$)\", fontsize=15)\n",
    "                x_ = \"width\"\n",
    "                plt.xscale('log')\n",
    "            else:\n",
    "                plt.xlabel(x, fontsize=15)\n",
    "                x_ = x\n",
    "\n",
    "            if y.endswith(\"percent_coverage\"):\n",
    "                plt.ylabel(r\"Percent Coverage ($\\rightarrow$)\", fontsize=15)\n",
    "                y_ = \"coverage\"\n",
    "                plt.ylim((-0.05,1.05))\n",
    "            elif y.endswith(\"miscalibration_area\"):\n",
    "                plt.ylabel(r\"Miscalibration Area ($\\leftarrow$)\", fontsize=15)\n",
    "                y_ = \"area\"\n",
    "                plt.ylim((-0.05,0.55))\n",
    "            else:\n",
    "                plt.ylabel(y, fontsize=15)\n",
    "                y_ = y\n",
    "                \n",
    "            plt.title(f\"{landscape} ({representation.upper()})\", fontsize=15)\n",
    "\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')            \n",
    "\n",
    "            plt.xticks(fontsize=12)\n",
    "            plt.yticks(fontsize=12)\n",
    "\n",
    "            plt.savefig(f\"{landscape.lower()}_{representation}_{y_}_{x_}.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c9df17",
   "metadata": {},
   "source": [
    "#### Figure 2, Figure S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a637c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_two_vars('test_rmse', 'test_miscalibration_area')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4df6b5",
   "metadata": {},
   "source": [
    "#### Figure 3, Figure S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809c32af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_two_vars('test_average_width_range', 'test_percent_coverage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd83db",
   "metadata": {},
   "source": [
    "# LaTeX Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d883a3a",
   "metadata": {},
   "source": [
    "#### Tables S1-S22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591a579",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col_to_table_list = [\n",
    "    'test_rmse', 'test_mae', # can't compare across datasets with different units\n",
    "    'test_r2', \n",
    "    'test_rho', 'test_rho_unc',\n",
    "    'test_percent_coverage', 'test_average_width_range',\n",
    "    'test_miscalibration_area', \n",
    "    'test_average_nll', 'test_average_optimal_nll', 'test_average_nll_ratio', \n",
    "]\n",
    "\n",
    "col_to_label_dict = {\n",
    "    'test_r2': r\"Test $R^2$ ($\\rightarrow$)\", \n",
    "    'test_rho': r\"Test $\\rho$ ($\\rightarrow$)\", \n",
    "    'test_rho_unc': r\"Test $\\rho_{unc}$ ($\\rightarrow$)\",\n",
    "    'test_percent_coverage': r\"Test % Coverage ($\\rightarrow$)\", \n",
    "    'test_average_width_range': r\"Test $4\\sigma/R$ ($\\leftarrow$)\",\n",
    "    'test_miscalibration_area': r\"Test Miscalibration Area ($\\leftarrow$)\", \n",
    "    'test_average_nll': r\"Test $\\overline{NLL}$ ($\\leftarrow$)\", \n",
    "    'test_average_optimal_nll': r\"Test $\\overline{NLL_{opt}}$\", \n",
    "    'test_average_nll_ratio': r\"Test $\\overline{NLL}$ / $\\overline{NLL_{opt}} Ratio$ ($\\leftarrow$)\",\n",
    "    'test_rmse': r\"Test RMSE ($\\leftarrow$)\", \n",
    "    'test_mae': r\"Test MAE ($\\leftarrow$)\", \n",
    "}\n",
    "\n",
    "col_to_cbar = {\n",
    "    'test_r2': {'fmt': \".3f\", \"norm\": None}, \n",
    "    'test_rho': {'fmt': \".3f\", \"norm\": None}, \n",
    "    'test_rho_unc': {'fmt': \".3f\", \"norm\": None},\n",
    "    'test_percent_coverage': {'fmt': \".3f\", \"norm\": None}, \n",
    "    'test_average_width_range': {'fmt': \".1e\", \"norm\": LogNorm(), \"annot_kws\": {\"size\":8}},\n",
    "    'test_miscalibration_area': {'fmt': \".3f\", \"norm\": None}, \n",
    "    'test_average_nll': {'fmt': \".1e\", \"norm\": LogNorm(), \"annot_kws\": {\"size\":8}}, \n",
    "    'test_average_optimal_nll': {'fmt': \".3f\", \"norm\": None}, \n",
    "    'test_average_nll_ratio': {'fmt': \".1e\", \"norm\": LogNorm(), \"annot_kws\": {\"size\":8}},\n",
    "    'test_rmse': {'fmt': \".3f\", \"norm\": None}, \n",
    "    'test_mae': {'fmt': \".3f\", \"norm\": None}, \n",
    "}\n",
    "\n",
    "for rep in ['ohe','esm']:\n",
    "    for col in col_to_table_list: \n",
    "        df_pivot = results_df.loc[results_df.representation==rep].pivot(index=['Dataset','Split'], \n",
    "                                                                           columns='Model', \n",
    "                                                                           values=col)\n",
    "        #print(rep, col)\n",
    "        print()\n",
    "        print(df_pivot.to_latex(float_format=\"{:0.3f}\".format))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79371c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bio-benchmarks]",
   "language": "python",
   "name": "conda-env-bio-benchmarks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
